{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Mean Machine: Decision Tree Part 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will implement your own binary decision tree classifier. The tasks herewith are to\n",
    "    \n",
    "* Use pandas to do some feature engineering.\n",
    "* Transform categorical variables into binary variables.\n",
    "* Write a function to compute the number of misclassified examples in an intermediate node.\n",
    "* Write a function to find the best feature to split on.\n",
    "* Build a binary decision tree from scratch.\n",
    "* Make predictions using the decision tree.\n",
    "* Evaluate the accuracy of the decision tree.\n",
    "* Visualize the decision at the root node.\n",
    "\n",
    "**Important Note**: In this notebook, we will onlyfocus on building decision trees where the data contain **only binary (0 or 1) features**. This allows us to avoid dealing with:\n",
    "* Multiple intermediate nodes in a split\n",
    "* The thresholding issues of real-valued features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Import all relevant packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np     # 用来做数学运算\n",
    "import pandas as pd    # 用来处理数据表\n",
    "from sklearn.model_selection import train_test_split # 做交叉验证，划分训练集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font color='red'>Load Lending Club dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same [LendingClub](https://www.lendingclub.com/) dataset as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>collections_12_mths_zero</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>final_d</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_record_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.143500</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.393200</td>\n",
       "      <td>20161201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.259550</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122604</th>\n",
       "      <td>9695736</td>\n",
       "      <td>11547808</td>\n",
       "      <td>8525</td>\n",
       "      <td>8525</td>\n",
       "      <td>8525</td>\n",
       "      <td>60 months</td>\n",
       "      <td>18.25</td>\n",
       "      <td>217.65</td>\n",
       "      <td>D</td>\n",
       "      <td>D3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.958120</td>\n",
       "      <td>20190101T000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122605</th>\n",
       "      <td>9684700</td>\n",
       "      <td>11536848</td>\n",
       "      <td>22000</td>\n",
       "      <td>22000</td>\n",
       "      <td>22000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>19.97</td>\n",
       "      <td>582.50</td>\n",
       "      <td>D</td>\n",
       "      <td>D5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.961540</td>\n",
       "      <td>20190101T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122606</th>\n",
       "      <td>9604874</td>\n",
       "      <td>11457002</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.90</td>\n",
       "      <td>62.59</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904916</td>\n",
       "      <td>20170101T000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "0       1077501    1296599       5000         5000             4975   \n",
       "1       1077430    1314167       2500         2500             2500   \n",
       "2       1077175    1313524       2400         2400             2400   \n",
       "122604  9695736   11547808       8525         8525             8525   \n",
       "122605  9684700   11536848      22000        22000            22000   \n",
       "122606  9604874   11457002       2000         2000             2000   \n",
       "\n",
       "              term  int_rate  installment grade sub_grade  \\\n",
       "0        36 months     10.65       162.87     B        B2   \n",
       "1        60 months     15.27        59.83     C        C4   \n",
       "2        36 months     15.96        84.33     C        C5   \n",
       "122604   60 months     18.25       217.65     D        D3   \n",
       "122605   60 months     19.97       582.50     D        D5   \n",
       "122606   36 months      7.90        62.59     A        A4   \n",
       "\n",
       "                ...          sub_grade_num delinq_2yrs_zero pub_rec_zero  \\\n",
       "0               ...                    0.4              1.0          1.0   \n",
       "1               ...                    0.8              1.0          1.0   \n",
       "2               ...                    1.0              1.0          1.0   \n",
       "122604          ...                    0.6              0.0          1.0   \n",
       "122605          ...                    1.0              1.0          0.0   \n",
       "122606          ...                    0.8              0.0          1.0   \n",
       "\n",
       "        collections_12_mths_zero short_emp payment_inc_ratio          final_d  \\\n",
       "0                            1.0         0          8.143500  20141201T000000   \n",
       "1                            1.0         1          2.393200  20161201T000000   \n",
       "2                            1.0         0          8.259550  20141201T000000   \n",
       "122604                       1.0         0          6.958120  20190101T000000   \n",
       "122605                       1.0         0          8.961540  20190101T000000   \n",
       "122606                       1.0         0          0.904916  20170101T000000   \n",
       "\n",
       "       last_delinq_none last_record_none last_major_derog_none  \n",
       "0                     1                1                     1  \n",
       "1                     1                1                     1  \n",
       "2                     1                1                     1  \n",
       "122604                0                1                     0  \n",
       "122605                1                0                     1  \n",
       "122606                0                1                     1  \n",
       "\n",
       "[6 rows x 68 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans = pd.read_csv('lending-club-data.csv', low_memory=False)\n",
    "loans.head(3).append(loans.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reassign the labels to have +1 for a safe loan, and -1 for a risky (bad) loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.drop('bad_loans', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will just use 4 categorical features: \n",
    "\n",
    "1. grade of the loan \n",
    "2. the length of the loan term\n",
    "3. the home ownership status: own, mortgage, rent\n",
    "4. number of years of employment.\n",
    "\n",
    "Since we are building a binary decision tree, we will have to convert these categorical features to a binary representation in a subsequent section using 1-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>term</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>safe_loans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>60 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122604</th>\n",
       "      <td>D</td>\n",
       "      <td>60 months</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>5 years</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122605</th>\n",
       "      <td>D</td>\n",
       "      <td>60 months</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122606</th>\n",
       "      <td>A</td>\n",
       "      <td>36 months</td>\n",
       "      <td>OWN</td>\n",
       "      <td>3 years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade        term home_ownership emp_length  safe_loans\n",
       "0          B   36 months           RENT  10+ years           1\n",
       "1          C   60 months           RENT   < 1 year          -1\n",
       "2          C   36 months           RENT  10+ years           1\n",
       "122604     D   60 months       MORTGAGE    5 years          -1\n",
       "122605     D   60 months       MORTGAGE  10+ years          -1\n",
       "122606     A   36 months            OWN    3 years           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.head(3).append(loans.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample dataset to make sure classes are balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will undersample the larger class (safe loans) in order to balance out our dataset. This means we are throwing away many data points. We use `seed=1` so everyone gets the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of safe loans  : 50.00%\n",
      "% of risky loans : 50.00%\n",
      "Total number of loans in our new dataset : 46300\n"
     ]
    }
   ],
   "source": [
    "safe_loans_raw = loans[loans[target] == +1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "ratio = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "\n",
    "risky_loans = risky_loans_raw\n",
    "safe_loans = safe_loans_raw.sample(frac=ratio, random_state=1)\n",
    "\n",
    "# Append the risky_loans with the downsampled version of safe_loans\n",
    "loans_data = risky_loans.append(safe_loans)\n",
    "\n",
    "N1 = len(safe_loans)\n",
    "N2 = len(risky_loans)\n",
    "N = N1 + N2\n",
    "print( \"%% of safe loans  : %.2f%%\" %(N1/N*100.0) )\n",
    "print( \"%% of risky loans : %.2f%%\" %(N2/N*100.0) )\n",
    "print( \"Total number of loans in our new dataset :\", N )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical data into binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement **binary decision trees** (decision trees for binary features, a specific case of categorical variables taking on two values, e.g., true/false). Since all of our features are currently categorical features, we want to turn them into binary features. \n",
    "\n",
    "For instance, the **home_ownership** feature represents the home ownership status of the loanee, which is either `own`, `mortgage` or `rent`. For example, if a data point has the feature \n",
    "```\n",
    "   {'home_ownership': 'RENT'}\n",
    "```\n",
    "we want to turn this into three features: \n",
    "```\n",
    " { \n",
    "   'home_ownership = OWN'      : 0, \n",
    "   'home_ownership = MORTGAGE' : 0, \n",
    "   'home_ownership = RENT'     : 1\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade.C</th>\n",
       "      <th>grade.F</th>\n",
       "      <th>grade.B</th>\n",
       "      <th>grade.D</th>\n",
       "      <th>grade.A</th>\n",
       "      <th>grade.E</th>\n",
       "      <th>grade.G</th>\n",
       "      <th>term. 60 months</th>\n",
       "      <th>term. 36 months</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_length.3 years</th>\n",
       "      <th>emp_length.10+ years</th>\n",
       "      <th>emp_length.1 year</th>\n",
       "      <th>emp_length.9 years</th>\n",
       "      <th>emp_length.2 years</th>\n",
       "      <th>emp_length.8 years</th>\n",
       "      <th>emp_length.7 years</th>\n",
       "      <th>emp_length.5 years</th>\n",
       "      <th>emp_length.n/a</th>\n",
       "      <th>emp_length.6 years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90431</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115727</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105752</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        safe_loans  grade.C  grade.F  grade.B  grade.D  grade.A  grade.E  \\\n",
       "1               -1        1        0        0        0        0        0   \n",
       "6               -1        0        1        0        0        0        0   \n",
       "7               -1        0        0        1        0        0        0   \n",
       "90431            1        0        0        1        0        0        0   \n",
       "115727           1        0        1        0        0        0        0   \n",
       "105752           1        0        0        0        1        0        0   \n",
       "\n",
       "        grade.G  term. 60 months  term. 36 months         ...          \\\n",
       "1             0                1                0         ...           \n",
       "6             0                1                0         ...           \n",
       "7             0                1                0         ...           \n",
       "90431         0                0                1         ...           \n",
       "115727        0                1                0         ...           \n",
       "105752        0                1                0         ...           \n",
       "\n",
       "        emp_length.3 years  emp_length.10+ years  emp_length.1 year  \\\n",
       "1                        0                     0                  0   \n",
       "6                        0                     0                  0   \n",
       "7                        0                     0                  0   \n",
       "90431                    0                     0                  0   \n",
       "115727                   1                     0                  0   \n",
       "105752                   0                     0                  1   \n",
       "\n",
       "        emp_length.9 years  emp_length.2 years  emp_length.8 years  \\\n",
       "1                        0                   0                   0   \n",
       "6                        0                   0                   0   \n",
       "7                        0                   0                   0   \n",
       "90431                    0                   0                   1   \n",
       "115727                   0                   0                   0   \n",
       "105752                   0                   0                   0   \n",
       "\n",
       "        emp_length.7 years  emp_length.5 years  emp_length.n/a  \\\n",
       "1                        0                   0               0   \n",
       "6                        0                   0               0   \n",
       "7                        0                   0               0   \n",
       "90431                    0                   0               0   \n",
       "115727                   0                   0               0   \n",
       "105752                   0                   0               0   \n",
       "\n",
       "        emp_length.6 years  \n",
       "1                        0  \n",
       "6                        0  \n",
       "7                        0  \n",
       "90431                    0  \n",
       "115727                   0  \n",
       "105752                   0  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_variables = []\n",
    "for feat_name, feat_type in zip(loans_data.columns.values,loans_data.dtypes):\n",
    "    if feat_type == object:\n",
    "        categorical_variables.append(feat_name)\n",
    "\n",
    "for feature in categorical_variables:\n",
    "    feat_value = loans_data[feature].unique()\n",
    "    loans_data_one_hot_encoded = pd.DataFrame()\n",
    "    for val in feat_value:\n",
    "        label = feature + '.' + val\n",
    "        loans_data_one_hot_encoded[label] = loans_data[feature].apply(lambda x: 1 if x == val else 0)\n",
    "    loans_data = pd.concat([loans_data, loans_data_one_hot_encoded], axis=1)\n",
    "loans_data = loans_data.drop(categorical_variables,axis=1)\n",
    "\n",
    "loans_data.head(3).append(loans_data.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the feature columns look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['grade.C', 'grade.F', 'grade.B', 'grade.D', 'grade.A', 'grade.E',\n",
       "       'grade.G', 'term. 60 months', 'term. 36 months',\n",
       "       'home_ownership.RENT', 'home_ownership.OWN',\n",
       "       'home_ownership.MORTGAGE', 'home_ownership.OTHER',\n",
       "       'emp_length.< 1 year', 'emp_length.4 years', 'emp_length.3 years',\n",
       "       'emp_length.10+ years', 'emp_length.1 year', 'emp_length.9 years',\n",
       "       'emp_length.2 years', 'emp_length.8 years', 'emp_length.7 years',\n",
       "       'emp_length.5 years', 'emp_length.n/a', 'emp_length.6 years'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = loans_data.columns.values\n",
    "features = features[features != target]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features (after one-hot encoding) = 25\n"
     ]
    }
   ],
   "source": [
    "print( \"# of features (after one-hot encoding) = %s\" % len(features) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "We split the data into a train test split with 80% of the data in the training set and 20% of the data in the test set. We use `random_state=0` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37040, 26) (9260, 26)\n"
     ]
    }
   ],
   "source": [
    "(train_data, test_data) = train_test_split( loans_data, \n",
    "                          train_size=0.8, random_state=0 )\n",
    "print( train_data.shape, test_data.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Decision tree implementation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will implement binary decision trees from scratch. There are several steps involved in building a decision tree. For that reason, we have split the entire assignment into several sections.\n",
    "\n",
    "## Function to count number of mistakes while predicting majority class\n",
    "\n",
    "Prediction at an intermediate node works by predicting the **majority class** for all data points that belong to this node.\n",
    "\n",
    "Now, we will write a function that calculates the number of **missclassified examples** when predicting the **majority class**. This will be used to help determine which feature is the best to split on at a given node of the tree.\n",
    "\n",
    "**Note**: Keep in mind that in order to compute the number of mistakes for a majority classifier, we only need the label (y values) of the data points in the node. \n",
    "\n",
    "** Steps to follow **:\n",
    "* ** Step 1:** Calculate the number of safe loans and risky loans.\n",
    "* ** Step 2:** Since we are assuming majority class prediction, all the data points that are **not** in the majority class are considered **mistakes**.\n",
    "* ** Step 3:** Return the number of **mistakes**.\n",
    "\n",
    "\n",
    "Now, let us write the function `count_num_mistakes` which computes the number of misclassified examples of an intermediate node given the set of labels (y values) of the data points contained in the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_num_mistakes( labels_in_node ):\n",
    "    # Corner case: If labels_in_node is empty, return 0\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Count the number of 1's (safe loans)\n",
    "    counter1 = (labels_in_node == 1).sum()\n",
    "    \n",
    "    # Count the number of -1's (risky loans)\n",
    "    counter_1 = (labels_in_node == -1).sum()\n",
    "                \n",
    "    # Return the number of mistakes by majority rules\n",
    "    return counter_1 if counter1 >= counter_1 else counter1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are several steps in this assignment, we have introduced some stopping points where you can check your code and make sure it is correct before proceeding. To test your `count_num_mistakes` function, run the following code until you get a **Test passed!**, then you should proceed. Otherwise, you should spend some time figuring out where things went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n",
      "Test passed!\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test case 1\n",
    "example_labels = np.array([-1, -1, 1, 1, 1])\n",
    "if count_num_mistakes(example_labels) == 2:\n",
    "    print( 'Test passed!' )\n",
    "else:\n",
    "    print( 'Test 1 failed... try again!' )\n",
    "\n",
    "# Test case 2\n",
    "example_labels = np.array([-1, -1, 1, 1, 1, 1, 1])\n",
    "if count_num_mistakes(example_labels) == 2:\n",
    "    print( 'Test passed!' )\n",
    "else:\n",
    "    print( 'Test 2 failed... try again!' )\n",
    "    \n",
    "# Test case 3\n",
    "example_labels = np.array([-1, -1, -1, -1, -1, 1, 1])\n",
    "if count_num_mistakes(example_labels) == 2:\n",
    "    print( 'Test passed!' )\n",
    "else:\n",
    "    print( 'Test 3 failed... try again!' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to pick best feature to split on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **best_splitting_feature** takes 3 arguments: \n",
    "1. The data (a dataframe which includes all of the feature columns and label column)\n",
    "2. The features to consider for splits (a list of strings of column names to consider for splits)\n",
    "3. The name of the target/label column (string)\n",
    "\n",
    "The function will loop through the list of possible features, and consider splitting on each of them. It will calculate the classification error of each split and return the feature that had the smallest classification error when split on.\n",
    "\n",
    "Recall that the **classification error** is defined as follows:\n",
    "$$\n",
    "\\mbox{classification error} = \\frac{\\mbox{# mistakes}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "Follow these steps: \n",
    "* **Step 1:** Loop over each feature in the feature list\n",
    "* **Step 2:** Within the loop, split the data into two groups: one group where all of the data has feature value 0 or False (we will call this the **left** split), and one group where all of the data has feature value 1 or True (we will call this the **right** split). Make sure the **left** split corresponds with 0 and the **right** split corresponds with 1 to ensure your implementation fits with our implementation of the tree building process.\n",
    "* **Step 3:** Calculate the number of misclassified examples in both groups of data and use the above formula to compute the **classification error**.\n",
    "* **Step 4:** If the computed error is smaller than the best error found so far, store this **feature and its error**.\n",
    "\n",
    "\n",
    "**Note:** Remember that since we are only dealing with binary features, we do not have to consider thresholds for real-valued features. This makes the implementation of this function much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_splitting_feature( data, features, target ):\n",
    "    \n",
    "    best_feature = None # Keep track of the best feature \n",
    "    best_error = 10     # Keep track of the best error so far \n",
    "    # Note: Since error is always <= 1 so it's OK with some number > 1.\n",
    "\n",
    "    # Convert to float to make sure error gets computed correctly.\n",
    "    num_data_points = float(len(data))  \n",
    "    \n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        left_split = data[ data[feature] == 0 ]\n",
    "        \n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        right_split = data[ data[feature] == 1 ] \n",
    "            \n",
    "        # Calculate the number of misclassified examples in the left split.\n",
    "        left_mistakes = count_num_mistakes( left_split[target] )            \n",
    "\n",
    "        # Calculate the number of misclassified examples in the right split.\n",
    "        right_mistakes = count_num_mistakes( right_split[target] ) \n",
    "            \n",
    "        # Compute the classification error of this split.\n",
    "        # Error = (# of mistakes (left) + # of mistakes (right)) / (# of data points)\n",
    "        error = (left_mistakes + right_mistakes) / num_data_points\n",
    "\n",
    "        # If this is the best error we have found so far, \n",
    "        # store the feature as best_feature and the error as best_error\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "    \n",
    "    return best_feature # Return the best feature we found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the tree\n",
    "\n",
    "With the above functions implemented correctly, we are now ready to build our decision tree. Each node in the decision tree is represented as a dictionary which contains the following keys and possible values:\n",
    "\n",
    "    { \n",
    "       'is_leaf'            : True/False.\n",
    "       'prediction'         : Prediction at the leaf node.\n",
    "       'left'               : (dictionary corresponding to the left tree).\n",
    "       'right'              : (dictionary corresponding to the right tree).\n",
    "       'splitting_feature'  : The feature that this node splits on.\n",
    "    }\n",
    "\n",
    "First, we will write a function that creates a leaf node given a set of target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf( target_values ):\n",
    "\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True }\n",
    "    \n",
    "    # Count the number of data points that are +1 and -1 in this node.\n",
    "    num_ones = len( target_values[target_values == +1] )\n",
    "    num_minus_ones = len( target_values[target_values == -1] )\n",
    "    \n",
    "    # For the leaf node, set the prediction to be the majority class.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    leaf['prediction'] = 1 if num_ones > num_minus_ones else -1\n",
    "     \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided a function that learns the decision tree recursively and implements 3 stopping conditions:\n",
    "1. **Stopping condition 1:** All data points in a node are from the same class.\n",
    "2. **Stopping condition 2:** No more features to split on.\n",
    "3. **Additional stopping condition:** Set **max_depth** of the tree. By not letting the tree grow too deep, we will save computational effort in the learning process. \n",
    "\n",
    "Now, we will write down the skeleton of the learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree( data, features, target, current_depth = 0, max_depth = 10 ):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    \n",
    "    target_values = data[target]\n",
    "    print( \"--------------------------------------------------------------------\" )\n",
    "    print( \"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)) )\n",
    "    \n",
    "    # Stopping condition 1: Check if there are mistakes at current node.\n",
    "    if count_num_mistakes(target_values) == 0:\n",
    "        print( \"Stopping condition 1 reached.\" )     \n",
    "        # If not mistakes at current node, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Stopping condition 2: Check if there are remaining features to consider splitting on\n",
    "    if len(remaining_features) == 0:\n",
    "        print( \"Stopping condition 2 reached.\" )    \n",
    "        # If there are no remaining features to consider, make current node a leaf node\n",
    "        return create_leaf(target_values)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth >= max_depth:\n",
    "        print( \"Reached maximum depth. Stopping for now.\" )\n",
    "        # If the max tree depth has been reached, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "\n",
    "    # Find the best splitting feature\n",
    "    splitting_feature = best_splitting_feature( data, features, target )\n",
    "    \n",
    "    # Split on the best feature that we found. \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    remaining_features = remaining_features[remaining_features != splitting_feature]\n",
    "    print( \"Split on feature %s. (%s, %s)\" % (\\\n",
    "                      splitting_feature, len(left_split), len(right_split)) )\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print( \"Creating leaf node.\" )\n",
    "        return create_leaf(left_split[target])\n",
    "    if len(right_split) == len(data):\n",
    "        print( \"Creating leaf node.\" )\n",
    "        return create_leaf(right_split[target])\n",
    "     \n",
    "    # Repeat on left and right subtrees\n",
    "    left_tree = decision_tree( left_split, remaining_features, target, current_depth + 1, max_depth )        \n",
    "    right_tree = decision_tree( right_split, remaining_features, target, current_depth + 1, max_depth )  \n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a recursive function to count the nodes in your tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes( tree ):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following test code to check your implementation. Make sure you get **'Test passed'** before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37040 data points).\n",
      "Split on feature term. 60 months. (27703, 9337)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (27703 data points).\n",
      "Split on feature grade.D. (23068, 4635)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23068 data points).\n",
      "Split on feature grade.E. (21809, 1259)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (21809 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1259 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4635 data points).\n",
      "Split on feature grade.C. (4635, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9337 data points).\n",
      "Split on feature grade.A. (9216, 121)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9216 data points).\n",
      "Split on feature grade.C. (6980, 2236)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (6980 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2236 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (121 data points).\n",
      "Split on feature emp_length.n/a. (115, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (115 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (6 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "small_data_decision_tree = decision_tree( train_data, features, 'safe_loans', max_depth = 3 )\n",
    "if count_nodes(small_data_decision_tree) == 13:\n",
    "    print( 'Test passed!' )\n",
    "else:\n",
    "    print( 'Test failed... try again!' )\n",
    "    print( 'Number of nodes found                :', count_nodes(small_data_decision_tree) )\n",
    "    print( 'Number of nodes that should be there : 13' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the tree!\n",
    "\n",
    "Now that all the tests are passing, we will train a tree model on the **train_data**. Limit the depth to 6 (**max_depth = 6**) to make sure the algorithm doesn't run for too long. Call this tree **my_decision_tree**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37040 data points).\n",
      "Split on feature term. 60 months. (27703, 9337)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (27703 data points).\n",
      "Split on feature grade.D. (23068, 4635)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23068 data points).\n",
      "Split on feature grade.E. (21809, 1259)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (21809 data points).\n",
      "Split on feature grade.C. (14639, 7170)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (14639 data points).\n",
      "Split on feature grade.F. (14265, 374)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (14265 data points).\n",
      "Split on feature grade.G. (14164, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (14164 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (101 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (374 data points).\n",
      "Split on feature grade.B. (374, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (7170 data points).\n",
      "Split on feature home_ownership.MORTGAGE. (4328, 2842)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4328 data points).\n",
      "Split on feature emp_length.3 years. (3914, 414)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3914 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (414 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2842 data points).\n",
      "Split on feature emp_length.n/a. (2718, 124)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2718 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (124 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1259 data points).\n",
      "Split on feature grade.C. (1259, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4635 data points).\n",
      "Split on feature grade.C. (4635, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9337 data points).\n",
      "Split on feature grade.A. (9216, 121)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9216 data points).\n",
      "Split on feature grade.C. (6980, 2236)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (6980 data points).\n",
      "Split on feature grade.F. (5658, 1322)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5658 data points).\n",
      "Split on feature grade.B. (4606, 1052)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4606 data points).\n",
      "Split on feature grade.D. (2513, 2093)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2513 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2093 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1052 data points).\n",
      "Split on feature emp_length.5 years. (981, 71)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (981 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (71 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1322 data points).\n",
      "Split on feature grade.B. (1322, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2236 data points).\n",
      "Split on feature grade.F. (2236, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (121 data points).\n",
      "Split on feature emp_length.n/a. (115, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (115 data points).\n",
      "Split on feature emp_length.1 year. (112, 3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (112 data points).\n",
      "Split on feature grade.C. (112, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3 data points).\n",
      "Split on feature grade.C. (3, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (6 data points).\n",
      "Split on feature grade.C. (6, 0)\n",
      "Creating leaf node.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree = decision_tree( train_data, features, 'safe_loans', max_depth = 6 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with a decision tree\n",
    "\n",
    "We can make predictions from the decision tree with a simple recursive function. Below, we call this function `classify`, which takes in a learned `tree` and a test point `x` to classify.  We include an option `annotate` that describes the prediction path when set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify( tree, x, annotate = False ):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print( \"At leaf, predicting %s\" % tree['prediction'] )\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print( \"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value) )\n",
    "        if split_feature_value == 0:\n",
    "            return classify( tree['left'], x, annotate )\n",
    "        else:\n",
    "            return classify( tree['right'], x, annotate )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider the first example of the test set and see what `my_decision_tree` model predicts for this data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "safe_loans                -1\n",
       "grade.C                    0\n",
       "grade.F                    0\n",
       "grade.B                    0\n",
       "grade.D                    0\n",
       "grade.A                    0\n",
       "grade.E                    1\n",
       "grade.G                    0\n",
       "term. 60 months            1\n",
       "term. 36 months            0\n",
       "home_ownership.RENT        0\n",
       "home_ownership.OWN         1\n",
       "home_ownership.MORTGAGE    0\n",
       "home_ownership.OTHER       0\n",
       "emp_length.< 1 year        0\n",
       "emp_length.4 years         0\n",
       "emp_length.3 years         1\n",
       "emp_length.10+ years       0\n",
       "emp_length.1 year          0\n",
       "emp_length.9 years         0\n",
       "emp_length.2 years         0\n",
       "emp_length.8 years         0\n",
       "emp_length.7 years         0\n",
       "emp_length.5 years         0\n",
       "emp_length.n/a             0\n",
       "emp_length.6 years         0\n",
       "Name: 16626, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term. 60 months = 1\n",
      "Split on grade.A = 0\n",
      "Split on grade.C = 0\n",
      "Split on grade.F = 0\n",
      "Split on grade.B = 0\n",
      "Split on grade.D = 0\n",
      "At leaf, predicting -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify( my_decision_tree, test_data.iloc[0], annotate=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating your decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will write a function to evaluate a decision tree by computing the classification error of the tree on the given dataset.\n",
    "\n",
    "Again, recall that the **classification error** is defined as follows:\n",
    "$$\n",
    "\\mbox{classification error} = \\frac{\\mbox{# mistakes}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "Now, write a function called `misclassify_error` that takes in as input:\n",
    "1. `tree` (as described above)\n",
    "2. `data` (a dataframe)\n",
    "\n",
    "This function should return a prediction (class label) for each row in `data` using the decision `tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassify_error( tree, data ):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    prediction = data.apply( lambda x: classify(tree, x), axis=1 )\n",
    "    true_label = data[\"safe_loans\"]\n",
    "    return (prediction!=true_label).sum() / float(len(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use this function to evaluate the classification error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39146868250539957"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassify_error( my_decision_tree, test_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing out a decision stump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out a single decision stump "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stump( tree, name = 'root' ):\n",
    "    split_name = tree['splitting_feature']\n",
    "    if split_name is None:\n",
    "        print( \"(leaf, label: %s)\" % tree['prediction'] )\n",
    "        return None\n",
    "    split_feature, split_value = split_name.split('.')\n",
    "    print( '                       %s' % name          )\n",
    "    print( '         |---------------|----------------|')\n",
    "    print( '         |                                |')\n",
    "    print( '         |                                |')\n",
    "    print( '         |                                |')\n",
    "    print( '  [{0} == 0]               [{0} == 1]    '.format(split_name))\n",
    "    print( '         |                                |')\n",
    "    print( '         |                                |')\n",
    "    print( '         |                                |')\n",
    "    print( '    (%s)                         (%s)' \\\n",
    "        % (('leaf, label: ' + str(tree['left']['prediction']) \\\n",
    "            if tree['left']['is_leaf'] else 'subtree'),\n",
    "           ('leaf, label: ' + str(tree['right']['prediction']) \\\n",
    "            if tree['right']['is_leaf'] else 'subtree')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [term. 60 months == 0]               [term. 60 months == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump( my_decision_tree )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the left subtree\n",
    "\n",
    "The tree is a recursive dictionary, so we do have access to all the nodes! We can use\n",
    "* `my_decision_tree['left']` to go left\n",
    "* `my_decision_tree['right']` to go right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       term. 60 months\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade.D == 0]               [grade.D == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump( my_decision_tree['left'], my_decision_tree['splitting_feature'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the left of left subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       grade.D\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade.E == 0]               [grade.E == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump( my_decision_tree['left']['left'], my_decision_tree['left']['splitting_feature'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the right of left subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump( my_decision_tree['left']['right'], my_decision_tree['left']['splitting_feature'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the right subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       term. 60 months\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade.A == 0]               [grade.A == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump( my_decision_tree['right'], my_decision_tree['splitting_feature'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the right of right subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       grade.A\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [emp_length.n/a == 0]               [emp_length.n/a == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump( my_decision_tree['right']['right'], my_decision_tree['right']['splitting_feature'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the left of right subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       grade.A\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade.C == 0]               [grade.C == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump( my_decision_tree['right']['left'], my_decision_tree['right']['splitting_feature'] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
